{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Pytorch implementation\n",
    "via https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"I:/GAN-Art/datasets/wikiart_25/Expressionism_\"\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# filter in gen\n",
    "ngf = 96\n",
    "\n",
    "# filter in discriminator\n",
    "ndf = 36\n",
    "\n",
    "# latent vector dimension\n",
    "nz = 100\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Binary cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# latent vector generation\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# real, fake label convention\n",
    "real_label = 0.9\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelle\n",
    "\n",
    "zoo = {\"256px output\": (\n",
    "    nn.Sequential(\n",
    "        # Input Z (100x1x1)\n",
    "        nn.ConvTranspose2d(nz, ngf * 32, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 32),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 4x4x(ngf*32)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 32, ngf * 16, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 16),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 8x8x(ngf*16)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 8),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 16x16x(ngf*8)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 4),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 32x32x(ngf*4)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 2),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 64x64x(ngf*2)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 128x128x(ngf)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # 256x256x3 Output\n",
    "    ),\n",
    "    \n",
    "    nn.Sequential(\n",
    "        # Input 256x256x3\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 128x128xndf\n",
    "\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 64x64x(ndf * 2)\n",
    "\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 32x32x(ndf * 4)\n",
    "\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 16x16x(ndf * 8)\n",
    "\n",
    "        nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 16),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 8x8x(ndf * 16)\n",
    "\n",
    "        nn.Conv2d(ndf * 16, ndf * 32, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 4x4x(ndf * 32)\n",
    "\n",
    "        nn.Conv2d(ndf * 32, 1, 4, 1, 0, bias=False),\n",
    "        nn.Sigmoid()\n",
    "        # 1x1x1\n",
    "    )),\n",
    "        \"64px output\": (\n",
    "        nn.Sequential(\n",
    "        # Input Z (100x1x1)\n",
    "        nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 8),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 4x4x(ngf*8)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 4),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 8x8x(ngf*4)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 2),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 16x16x(ngf*2)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        # 32x32x(ngf)\n",
    "\n",
    "        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # 64x64x3 Output\n",
    "    ),\n",
    "    \n",
    "    nn.Sequential(\n",
    "        # Input 64x64x3\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 32x32xndf\n",
    "\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 16x16x(ndf * 2)\n",
    "\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 8x8x(ndf * 4)\n",
    "\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # 4x4x(ndf * 8)\n",
    "\n",
    "        nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "        nn.Sigmoid()\n",
    "        # 1x1x1    \n",
    "    ))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(img_size, batch_size, num_workers, plot_train):\n",
    "    dataset = dset.ImageFolder(root=dataroot,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize((img_size, img_size)),\n",
    "                              transforms.CenterCrop(img_size),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                          ]))\n",
    "\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    \n",
    "    if plot_train:\n",
    "        # Plot training data\n",
    "        real_batch = next(iter(dataloader))\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Training Images\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:32], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "        \n",
    "        \n",
    "    return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_losses(G_losses, D_losses):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(G_losses,label=\"G\")\n",
    "    plt.plot(D_losses,label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slider(img_list):\n",
    "    #%%capture\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "    ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    plt.show()\n",
    "    HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(foldername, num_samples=64, imgs_per_files = 16, check_path=None, \n",
    "              architecture=None, save_path=\"I:/GAN-Art/Jupyter/samples/\", model=None):\n",
    "    \n",
    "    gen = None\n",
    "    samples = None\n",
    "    num_files = int(num_samples / imgs_per_files)\n",
    "    noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "    folder_path = save_path + foldername + \"/\"\n",
    "    if not os.path.exists(folder_path): os.mkdir(folder_path) \n",
    "    \n",
    "    if check_path is not None and architecture is not None:\n",
    "        state = torch.load(check_path, map_location=\"cpu\")\n",
    "        gen, _ = create_architectures(architecture, False)\n",
    "        gen.load_state_dict(state[\"netG\"])\n",
    "        samples = gen(noise)\n",
    "\n",
    "    if model is not None:\n",
    "        samples = model(noise)\n",
    "       \n",
    "    # tuple of len 4\n",
    "    split = torch.split(samples, [imgs_per_files] * num_files, dim=0)\n",
    "    \n",
    "    # read files\n",
    "    onlyfiles = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    # strip strgs\n",
    "    lst = []\n",
    "    for x in onlyfiles:\n",
    "        lst.append(os.path.splitext(x)[0])\n",
    "        \n",
    "    lst = list(map(int, lst))\n",
    "    high = max(lst) if lst else 0\n",
    "    \n",
    "    print(\"Saving generated images to...\\n\")\n",
    "    j=0\n",
    "    for i in range(high, high+num_files):\n",
    "        filename = folder_path + (\"%s\"%(i+1))+\".png\"\n",
    "        open(filename, \"ab\")\n",
    "        print(filename)\n",
    "        \n",
    "        vutils.save_image(split[j], filename, nrow=4, padding=0, normalize=True)\n",
    "        \n",
    "        j += 1\n",
    "        \n",
    "\n",
    "        \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator/Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = architecture\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.main = architecture\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_architectures(architecture, print_summary):\n",
    "    # create architectures\n",
    "    netG = Generator(architecture[0]).to(device)\n",
    "    netD = Discriminator(architecture[1]).to(device)\n",
    "\n",
    "    # Initialize weights in layers\n",
    "    netG.apply(weights_init)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    # print summary\n",
    "    if print_summary:\n",
    "        print(netG)\n",
    "        print(netD)\n",
    "        \n",
    "    return netG, netD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(architecture, batch_size, image_size, num_epochs, lr, beta1, save_path=None, load_path=None, \n",
    "          save_state=False, save_epochs = 30, print_summary = False, num_workers=4, \n",
    "          plot_train=False, print_eval=True, genimgs_iter = 500):\n",
    "    \n",
    "    # Variables \n",
    "    state = {\n",
    "        \"epoch\": 0,\n",
    "        \"netD\" : None,\n",
    "        \"netG\" : None,\n",
    "        \"optimizerD\" : None,\n",
    "        \"optimizerG\" : None,\n",
    "        \"img_list\" : [],\n",
    "        \"G_losses\" : [],\n",
    "        \"D_losses\" : [] \n",
    "    }\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "    epochs_trained = 0\n",
    "    epochs_loaded = 0\n",
    "    elapsed = 0\n",
    "    \n",
    "    # Dataloader\n",
    "    dataloader = create_dataloader(image_size, batch_size, num_workers, plot_train)\n",
    "    \n",
    "    # create gen, discr\n",
    "    netG, netD = create_architectures(architecture, print_summary)\n",
    "\n",
    "    # Adam optimizers\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    # check, if checkpointed model should be loaded up\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path, map_location=\"cpu\")\n",
    "        \n",
    "        epochs_trained = state[\"epochs_trained\"]\n",
    "        epochs_loaded = state[\"epochs_trained\"]\n",
    "        #img_list = state[\"img_list\"]\n",
    "        G_losses = state[\"G_losses\"] \n",
    "        D_losses = state[\"D_losses\"]\n",
    "        \n",
    "        netD.load_state_dict(state[\"netD\"]) \n",
    "        netG.load_state_dict(state[\"netG\"])\n",
    "        optimizerD.load_state_dict(state[\"optimizerD\"])\n",
    "        optimizerG.load_state_dict(state[\"optimizerG\"])\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    if load_path is not None:\n",
    "        print(\"Continue training from model %s, with %d epochs already trained. Training for additional %d epochs.\\n\" \n",
    "             % (load_path, epochs_loaded, num_epochs))\n",
    "    else:\n",
    "        print(\"Training a new model for %d epochs.\\n\" % (num_epochs))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time.time()\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            #######################################\n",
    "            # Train Discriminator\n",
    "            # max log(G(x)) + log(1-D(G(z)))\n",
    "            #######################################\n",
    "\n",
    "            ## Erster Durchlauf: real batch\n",
    "            netD.zero_grad()\n",
    "            real_batch = data[0].to(device)     # [batchsize, 3, H, W]\n",
    "            b_size = real_batch.size(0)\n",
    "            labels = torch.full((b_size, ), real_label, device=device)\n",
    "\n",
    "            # classify real batch\n",
    "            out = netD(real_batch).view(-1)\n",
    "\n",
    "            # calculate loss\n",
    "            errD_real = criterion(out, labels)\n",
    "\n",
    "            # Calculate gradients\n",
    "            errD_real.backward()\n",
    "            D_x = out.mean().item()\n",
    "\n",
    "            ## Zweiter Durchlauf: fake data\n",
    "\n",
    "            # generate latent samples\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake_batch = netG(noise)\n",
    "            labels.fill_(fake_label)\n",
    "\n",
    "            # classify fake batch\n",
    "            out = netD(fake_batch.detach()).view(-1)\n",
    "\n",
    "            # calculate loss\n",
    "            errD_fake = criterion(out, labels)\n",
    "\n",
    "            # calculate gradients\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = out.mean().item()\n",
    "\n",
    "            # add gradients \n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            # update discriminator weights (optimizerD <-> vb mit architektur in discr)\n",
    "            optimizerD.step()\n",
    "\n",
    "\n",
    "\n",
    "            #######################################\n",
    "            # Train Generator\n",
    "            # max log(D(G(z))) \n",
    "            #######################################\n",
    "\n",
    "            netG.zero_grad()\n",
    "            labels.fill_(real_label)\n",
    "\n",
    "            # generate new latent sample (same as above)\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake_batch = netG(noise)\n",
    "\n",
    "            out = netD(fake_batch).view(-1)\n",
    "\n",
    "            # calculate generator loss\n",
    "            errG = criterion(out, labels)\n",
    "\n",
    "            # calculate gradients\n",
    "            errG.backward()\n",
    "            D_G_z2 = out.mean().item()\n",
    "\n",
    "            # update generator weights (optimizerG <-> vb mit architektur in gen)\n",
    "            optimizerG.step()\n",
    "\n",
    "\n",
    "\n",
    "            #######################################\n",
    "            # Evaluation statistics\n",
    "            #######################################\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f %s'\n",
    "                      % (epochs_trained, epochs_loaded+num_epochs, i, len(dataloader),\n",
    "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, \n",
    "                         (\"EpochTime: %.2fmin, TimeLeft: %.2fmin\" %(elapsed, (num_epochs-epoch)*elapsed) \n",
    "                          if (epoch is not 0 and i == 0) else \"\")))\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                # Save Losses for plotting later\n",
    "                G_losses.append(errG.item())\n",
    "                D_losses.append(errD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % genimgs_iter == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = netG(fixed_noise).detach().cpu()\n",
    "\n",
    "                imgrid = vutils.make_grid(fake[random.sample(range(64), 10)], padding=2, normalize=True, nrow=10)\n",
    "                img_list.append(imgrid)\n",
    "                plt.figure(figsize=(20,20))\n",
    "                plt.imshow(np.transpose(imgrid, (1, 2, 0)))\n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "            iters += 1\n",
    "            \n",
    "        # serialize data every few epochs\n",
    "        if (save_state == True and (epoch % save_epochs == 0) and save_path is not None and epoch is not 0):\n",
    "                \n",
    "            state[\"epochs_trained\"] = epochs_trained\n",
    "            state[\"netD\"] = netD.state_dict()\n",
    "            state[\"netG\"] = netG.state_dict()\n",
    "            state[\"optimizerD\"] = optimizerD.state_dict()\n",
    "            state[\"optimizerG\"] = optimizerG.state_dict()\n",
    "            #state[\"img_list\"] = img_list\n",
    "            state[\"G_losses\"] = G_losses\n",
    "            state[\"D_losses\"] = D_losses  \n",
    "\n",
    "            torch.save(state, save_path)\n",
    "            print(\"Model saved after %d iters.\\n\" % (iters))    \n",
    "            \n",
    "        # epoch timing\n",
    "        epochs_trained += 1\n",
    "        toc = time.time()\n",
    "        elapsed = (toc-tic)/60\n",
    "        \n",
    "\n",
    "    \n",
    "    if print_eval:\n",
    "        print_losses(G_losses, D_losses)\n",
    "        show_slider(img_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expressionism 240+ epochs\n",
    "\n",
    "model(architecture = zoo[\"256px output\"], batch_size=32, image_size=256, num_epochs=100, lr=0.0002, beta1=0.5,\n",
    "     save_path = \"I:/GAN-Art/Jupyter/checkpoints/256x_300eps_expressionism.pt\", \n",
    "     load_path = \"I:/GAN-Art/Jupyter/checkpoints/256x_300eps_expressionism.pt\",\n",
    "     save_state=True, save_epochs = 20, genimgs_iter = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
